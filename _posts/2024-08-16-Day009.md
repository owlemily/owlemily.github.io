---
title: <Day009> Naver Boostcamp AI Tech
date: 2024-08-16
layout: post
tags: [Naver Boostcamp, daily report]
---
## 학습 내용

- Linear Regression을 진행할 때 가정을 하고 진행한다.
    - 종속변수와 독립변수가 **선형성**을 만족할 것
    - 관측값들이 시간의 흐름에 따라 잔차가 특정 패턴을 보이면 안된다(**독립성**) → 시간의 영향을 받으면 안된다.
    - 잔차의 분산이 일정해야한다. (**등분산성**)
    - 잔차가 정규분포를 따른다(**정규성**)
- 최소제곱법(OLS→ Ordinary Least Squares, 최소자승법, 최소이승법)
    - 관측값yi와 예측값(mxi + b) 의 차이를 **잔차** 라고 한다. 이 잔차의 제곱합이 최소가 될 수 있도록 하는 m과 b를 추정하는 방법이다.

---

- 매개변수적 접근
    - 파라미터: 데이터로부터 학습시켜서 얻는 것
    - 이런 파라미터를 추정해 나가는 것
- Linear Classifier에서 편향 b의 역할?
    - input data에 영향을 주지 않고 output에만 영향을 준다.
    - 즉, 데이터와 상호작용하지 않는다.
- Softmax Classifier 소프트맥스 함수
    - 입력 데이터의 점수를 확률로 변환하는 역할.
    - 각 클래스에 속할 확률을 출력한다.
    - 출력값의 합이 1이 되도록 정규화하고, 각 클래스에 대한 확률을 제공한다.
- Sigmoid
    - 이진분류 문제에서 보통 사용.

---

## 피어세션

- 선형대수학(부분공간의 기저와 차원~전사함수와 일대일 함수)
